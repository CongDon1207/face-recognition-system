"""
Step 2: Capture â€“ chá»¥p khuÃ´n máº·t theo 5 gÃ³c vá»›i hÆ°á»›ng dáº«n chi tiáº¿t.
"""

import cv2
import numpy as np
from PySide6.QtCore import Qt, Signal, Slot
from PySide6.QtGui import QImage, QPixmap, QColor
from PySide6.QtWidgets import (
    QWidget,
    QVBoxLayout,
    QHBoxLayout,
    QLabel,
    QPushButton,
    QFrame,
    QGraphicsDropShadowEffect,
)

from UI.styles import Theme
from common.camera import CameraThread
from modules.face_analyzer import DistanceStatus, PoseType
from .face_processing_thread import FaceProcessingThread


class CaptureStep(QWidget):
    """BÆ°á»›c 2: chá»¥p 5 gÃ³c khuÃ´n máº·t."""

    finished = Signal(list)  # (pose_type, embedding, cropped_image)

    POSE_SEQUENCE = [
        PoseType.FRONTAL,
        PoseType.LEFT,
        PoseType.RIGHT,
        PoseType.UP,
        PoseType.DOWN
    ]

    POSE_NAMES = {
        PoseType.FRONTAL: "NhÃ¬n tháº³ng",
        PoseType.LEFT: "Xoay trÃ¡i",
        PoseType.RIGHT: "Xoay pháº£i",
        PoseType.UP: "Ngáº©ng lÃªn",
        PoseType.DOWN: "CÃºi xuá»‘ng",
    }

    def __init__(self):
        super().__init__()
        self.current_step_index = 0
        self.captured_data: list[tuple[PoseType, np.ndarray, np.ndarray]] = []
        self.latest_frame: np.ndarray | None = None  # LÆ°u frame má»›i nháº¥t
        self.last_yaw: float | None = None  # Khá»Ÿi táº¡o last_yaw

        self.camera_thread: CameraThread | None = None
        self.processor_thread = FaceProcessingThread()
        self.processor_thread.result_ready.connect(self._on_ai_result)
        self.processor_thread.model_loaded.connect(self._on_models_loaded)
        self.processor_thread.start()

        self.last_ai_result = {}  # Initialize as empty dict for new logic

        self._build_ui()

    # ------------------------------- UI setup ------------------------------- #
    def _build_ui(self):
        layout = QHBoxLayout(self)
        layout.setSpacing(30)

        # Panel camera
        camera_container = QFrame()
        camera_container.setProperty("class", "glass_panel")
        camera_layout = QVBoxLayout(camera_container)
        camera_layout.setAlignment(Qt.AlignCenter)

        self.camera_view = QLabel()
        self.camera_view.setAlignment(Qt.AlignCenter)
        self.camera_view.setFixedSize(400, 400)
        self.camera_view.setStyleSheet(
            f"background-color: #000; border: 3px solid {Theme.PRIMARY}; border-radius: 200px;"
        )
        camera_layout.addWidget(self.camera_view)

        self.instruction_label = QLabel("Äang táº£i mÃ´ hÃ¬nh AI...")
        self.instruction_label.setAlignment(Qt.AlignCenter)
        self.instruction_label.setStyleSheet(
            f"color: {Theme.PRIMARY}; font-size: 22px; font-weight: bold; padding: 15px;"
        )
        shadow = QGraphicsDropShadowEffect()
        shadow.setBlurRadius(15)
        shadow.setColor(QColor(Theme.PRIMARY))
        shadow.setOffset(0, 0)
        self.instruction_label.setGraphicsEffect(shadow)
        camera_layout.addWidget(self.instruction_label)

        self.distance_label = QLabel("Vui lÃ²ng chá»...")
        self.distance_label.setAlignment(Qt.AlignCenter)
        self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
        camera_layout.addWidget(self.distance_label)

        # NÃšt Chá»¥p thá»§ cÃ´ng
        self.capture_btn = QPushButton("ðŸ“¸ Chá»¥p")
        self.capture_btn.setFixedHeight(60)
        self.capture_btn.setStyleSheet(f"""
            QPushButton {{
                background-color: {Theme.PRIMARY};
                color: white;
                font-size: 20px;
                font-weight: bold;
                border: none;
                border-radius: 8px;
                padding: 10px;
            }}
            QPushButton:hover {{
                background-color: {Theme.SECONDARY_GREEN};
            }}
            QPushButton:disabled {{
                background-color: #555;
                color: #999;
            }}
        """)
        self.capture_btn.clicked.connect(self._on_manual_capture)
        self.capture_btn.setEnabled(False)
        camera_layout.addWidget(self.capture_btn)

        layout.addWidget(camera_container, 2)

        # Panel checklist
        checklist_container = QFrame()
        checklist_container.setProperty("class", "glass_panel")
        checklist_layout = QVBoxLayout(checklist_container)
        checklist_layout.setContentsMargins(20, 20, 20, 20)

        header = QLabel("Tiáº¿n trÃ¬nh quay cÃ¡c gÃ³c")
        header.setStyleSheet(
            f"color: {Theme.TEXT_WHITE}; font-size: 18px; font-weight: bold;"
        )
        checklist_layout.addWidget(header)

        self.checklist_labels: dict[PoseType, QLabel] = {}
        for pose in self.POSE_SEQUENCE:
            lbl = QLabel(f"â¬œ  {self.POSE_NAMES[pose]}")
            lbl.setStyleSheet(
                f"color: {Theme.TEXT_GRAY}; font-size: 16px; padding: 8px;"
            )
            self.checklist_labels[pose] = lbl
            checklist_layout.addWidget(lbl)

        checklist_layout.addStretch()

        cancel_btn = QPushButton("Há»§y")
        cancel_btn.setProperty("class", "danger_button")
        cancel_btn.clicked.connect(self._on_cancel)
        checklist_layout.addWidget(cancel_btn)

        layout.addWidget(checklist_container, 1)

    # -------------------------- Capture life-cycle -------------------------- #
    def _on_models_loaded(self, success: bool, msg: str):
        if success:
            self.instruction_label.setText("Sáºµn sÃ ng!")
            self.distance_label.setText("")
        else:
            self.instruction_label.setText("Lá»—i AI!")
            self.distance_label.setText(msg)

    def start_capture(self, user_id: str = "temp"):
        self.user_id = user_id
        self.current_step_index = 0
        self.captured_data.clear()
        self._reset_checklist()
        
        # Reset baseline pose tá»« FRONTAL
        self.processor_thread.reset_pose_state()

        self.camera_view.setText("âŒ›\n\nÄang khá»Ÿi Ä‘á»™ng camera...")
        self.camera_view.setStyleSheet(
            f"background-color: #000; border: 3px solid {Theme.PRIMARY}; "
            f"border-radius: 200px; color: {Theme.TEXT_GRAY}; font-size: 16px;"
        )

        if self.camera_thread is None or not self.camera_thread.isRunning():
            self.camera_thread = CameraThread()
            self.camera_thread.frame_captured.connect(self._on_frame)
            self.camera_thread.error_occurred.connect(self._on_camera_error)
            self.camera_thread.started.connect(self._on_camera_started)
            self.camera_thread.start()

    def stop(self):
        if self.camera_thread:
            self.camera_thread.stop()

    def reset_ui(self):
        self.stop()
        self._reset_checklist()
        self.current_step_index = 0
        self.captured_data.clear()
        self.camera_view.clear()
        self.instruction_label.setText("Chuáº©n bá»‹...")
        self.distance_label.clear()

    def _on_camera_started(self):
        # Clear text trong camera_view Ä‘á»ƒ sáºµn sÃ ng hiá»ƒn thá»‹ frame
        self.camera_view.clear()
        self.camera_view.setStyleSheet(
            f"background-color: #000; border: 3px solid {Theme.PRIMARY}; border-radius: 200px;"
        )
        self.distance_label.setText("")
        self._update_instruction()

    def _reset_checklist(self):
        for pose, lbl in self.checklist_labels.items():
            lbl.setText(f"â¬œ  {self.POSE_NAMES[pose]}")
            lbl.setStyleSheet(
                f"color: {Theme.TEXT_GRAY}; font-size: 16px; padding: 8px;"
            )

    def _update_instruction(self):
        if self.current_step_index >= len(self.POSE_SEQUENCE):
            self.instruction_label.setText("âœ… HoÃ n táº¥t!")
            return
        
        current_pose = self.POSE_SEQUENCE[self.current_step_index]
        pose_name = self.POSE_NAMES[current_pose]
        step_num = self.current_step_index + 1
        total = len(self.POSE_SEQUENCE)

        instructions = {
            PoseType.FRONTAL: "ðŸ‘¤ NHÃŒN THáº²NG vÃ o camera",
            PoseType.LEFT: "ðŸ‘ˆ XOAY Máº¶T SANG TRÃI",
            PoseType.RIGHT: "ðŸ‘‰ XOAY Máº¶T SANG PHáº¢I",
            PoseType.UP: "â¬†ï¸ NGáº¨NG Äáº¦U LÃŠN",
            PoseType.DOWN: "â¬‡ï¸ CÃšI Äáº¦U XUá»NG",
        }

        msg = f"{step_num}/{total}: {pose_name}\n\n{instructions.get(current_pose, '')}\n\nðŸ‘‰ Nháº¥n nÃºt CHá»¤P khi sáºµn sÃ ng"
        self.instruction_label.setText(msg)

    # ------------------------------- Frame loop ------------------------------ #
    @Slot(np.ndarray)
    def _on_frame(self, frame: np.ndarray):
        self.latest_frame = frame.copy()  # LÆ°u frame má»›i nháº¥t
        if self.current_step_index >= len(self.POSE_SEQUENCE):
            return
        if self.processor_thread.is_models_loaded:
            current_pose = self.POSE_SEQUENCE[self.current_step_index]
            self.processor_thread.update_frame(frame, current_pose)
        self._draw_ui_overlay(frame)

    def _on_ai_result(self, result: dict):
        self.last_ai_result = result
        
        distance_status = result["distance_status"]
        pose_instruction = result["pose_instruction"]
        pose_ok = result["pose_ok"]
        self.last_yaw = result["yaw"]
        
        # Cáº­p nháº­t UI hÆ°á»›ng dáº«n
        if distance_status == DistanceStatus.NO_FACE:
            self.distance_label.setText("âŒ KhÃ´ng tháº¥y khuÃ´n máº·t")
            self.distance_label.setStyleSheet("color: #FF6B6B; font-size: 16px;")
            self.capture_btn.setEnabled(False)
        elif distance_status == DistanceStatus.TOO_FAR:
            self.distance_label.setText(f"âš ï¸ {pose_instruction}")
            self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
            self.capture_btn.setEnabled(False)
        elif distance_status == DistanceStatus.TOO_CLOSE:
            self.distance_label.setText(f"âš ï¸ {pose_instruction}")
            self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
            self.capture_btn.setEnabled(False)
        else:
            # Distance OK -> Check Pose
            if pose_ok:
                 self.distance_label.setText(f"âœ… {pose_instruction}")
                 self.distance_label.setStyleSheet(f"color: {Theme.SECONDARY_GREEN}; font-size: 16px;")
                 self.capture_btn.setEnabled(True)
            else:
                 self.distance_label.setText(f"â„¹ï¸ {pose_instruction}")
                 self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
                 self.capture_btn.setEnabled(False)

    def _on_manual_capture(self):
        """Xá»­ lÃ½ khi ngÆ°á»i dÃ¹ng nháº¥n nÃºt Chá»¥p - Tá»‘i Æ°u hÃ³a: DÃ¹ng luÃ´n káº¿t quáº£ AI Ä‘Ã£ cache."""
        # Láº¥y káº¿t quáº£ AI má»›i nháº¥t
        if not self.last_ai_result or not self.last_ai_result.get("has_face"):
             self.distance_label.setText("âŒ ChÆ°a cÃ³ dá»¯ liá»‡u khuÃ´n máº·t")
             return

        # Kiá»ƒm tra láº¡i tráº¡ng thÃ¡i láº§n cuá»‘i (an toÃ n)
        dist_status = self.last_ai_result["distance_status"]
        pose_ok = self.last_ai_result["pose_ok"]
        
        if dist_status != DistanceStatus.OK:
             self.distance_label.setText("âŒ Khoáº£ng cÃ¡ch khÃ´ng há»£p lá»‡")
             return
             
        # Láº¥y dá»¯ liá»‡u Ä‘Ã£ tÃ­nh toÃ¡n sáºµn
        embedding = self.last_ai_result["embedding"]
        face_box = self.last_ai_result["face_box"]
        frame_analyzed = self.last_ai_result["frame"] # Frame Ä‘á»“ng bá»™ vá»›i káº¿t quáº£ AI
        
        if embedding is None or frame_analyzed is None:
             self.distance_label.setText("âŒ Dá»¯ liá»‡u lá»—i (No embedding/frame)")
             return

        # Crop khuÃ´n máº·t tá»« frame Ä‘Ã£ analyze (Ä‘áº£m báº£o box khá»›p vá»›i frame)
        x, y, w, h = face_box
        # Expand box má»™t chÃºt Ä‘á»ƒ crop Ä‘áº¹p hÆ¡n (tÃ¹y chá»n, á»Ÿ Ä‘Ã¢y giá»¯ nguyÃªn logic cÅ© hoáº·c thÃªm padding)
        # Logic cÅ©: cropped = frame[y:y+h, x:x+w]
        
        # ThÃªm padding an toÃ n
        img_h, img_w = frame_analyzed.shape[:2]
        # x, y, w, h are integers
        cropped = frame_analyzed[y : y + h, x : x + w]
        
        if cropped.size == 0:
             self.distance_label.setText("âŒ Lá»—i cáº¯t áº£nh")
             return

        # LÆ°u dá»¯ liá»‡u
        current_pose = self.POSE_SEQUENCE[self.current_step_index]
        self.captured_data.append((current_pose, embedding, cropped))
        self._mark_step_done(current_pose)
        
        # Hiá»‡u á»©ng chá»¥p (Optional: Playsound or Flash)
        
        # Chuyá»ƒn bÆ°á»›c tiáº¿p theo
        self.current_step_index += 1
        if self.current_step_index >= len(self.POSE_SEQUENCE):
            self.stop()
            self.finished.emit(self.captured_data)
        else:
            self._update_instruction()
            self.capture_btn.setEnabled(False)

    def _draw_ui_overlay(self, frame: np.ndarray):
        if not self.last_ai_result:
            self._display_frame(frame)
            return

        display_frame = frame.copy()
        
        # Láº¥y tráº¡ng thÃ¡i tá»« dict result (cÃ³ thá»ƒ lÃ  cá»§a frame trÆ°á»›c, nhÆ°ng dÃ¹ng Ä‘á»ƒ váº½ overlay cho frame hiá»‡n táº¡i)
        # LÆ°u Ã½: frame input cá»§a hÃ m nÃ y lÃ  frame Má»šI NHáº¤T tá»« camera, khÃ´ng pháº£i frame trong result.
        # Overlay cÃ³ thá»ƒ bá»‹ lá»‡ch nháº¹ náº¿u váº­t thá»ƒ di chuyá»ƒn nhanh, nhÆ°ng cháº¥p nháº­n Ä‘Æ°á»£c cho realtime feedback.
        
        dist_status = self.last_ai_result.get("distance_status", DistanceStatus.NO_FACE)
        pose_ok = self.last_ai_result.get("pose_ok", False)
        
        border_color = Theme.DANGER_RED
        if dist_status == DistanceStatus.OK and pose_ok:
            border_color = Theme.SECONDARY_GREEN
        elif dist_status == DistanceStatus.OK:
            border_color = "#FFD700" # Warning color for wrong pose
            
        h, w = display_frame.shape[:2]
        color_bgr = self._hex_to_bgr(border_color)
        cv2.rectangle(display_frame, (10, 10), (w - 10, h - 10), color_bgr, 3)

        # Hiá»ƒn thá»‹ giÃ¡ trá»‹ Ratio á»Ÿ gÃ³c dÆ°á»›i bÃªn trÃ¡i Ä‘á»ƒ debug
        yaw_text = "Ratio: --"
        if self.last_yaw is not None:
            yaw_text = f"Ratio: {self.last_yaw:.2f}"
        
        cv2.putText(
            display_frame,
            yaw_text,
            (20, h - 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            self._hex_to_bgr("#FFFFFF"),
            2,
            cv2.LINE_AA,
        )

        self._display_frame(display_frame)

    # ------------------------- Capture & finish flow ------------------------ #
    def _mark_step_done(self, pose: PoseType):
        """ÄÃ¡nh dáº¥u bÆ°á»›c Ä‘Ã£ hoÃ n thÃ nh."""
        lbl = self.checklist_labels[pose]
        lbl.setText(f"âœ…  {self.POSE_NAMES[pose]}")
        lbl.setStyleSheet(
            f"color: {Theme.SECONDARY_GREEN}; font-size: 16px; padding: 8px; font-weight: bold;"
        )

    def _on_cancel(self):
        self.stop()
        self.finished.emit([])

    def _on_camera_error(self, msg: str):
        self.instruction_label.setText(f"Lá»—i camera: {msg}")
        self.distance_label.setText("Vui lÃ²ng kiá»ƒm tra láº¡i camera.")

    # -------------------------- Helper hiá»ƒn thá»‹ ----------------------------- #
    def _display_frame(self, frame: np.ndarray):
        # Äáº£m báº£o clear text náº¿u cÃ²n (first frame)
        if self.camera_view.text():
            self.camera_view.clear()
            self.camera_view.setStyleSheet(
                f"background-color: #000; border: 3px solid {Theme.PRIMARY}; border-radius: 200px;"
            )
        
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb.shape
        bytes_per_line = ch * w
        q_img = QImage(rgb.data, w, h, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_img)
        scaled = pixmap.scaled(
            400, 400, Qt.KeepAspectRatioByExpanding, Qt.SmoothTransformation
        )
        self.camera_view.setPixmap(scaled)

    def _hex_to_bgr(self, hex_color: str) -> tuple[int, int, int]:
        hex_color = hex_color.lstrip("#")
        r = int(hex_color[0:2], 16)
        g = int(hex_color[2:4], 16)
        b = int(hex_color[4:6], 16)
        return b, g, r
