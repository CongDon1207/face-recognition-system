"""
Step 2: Capture ‚Äì ch·ª•p khu√¥n m·∫∑t theo 5 g√≥c v·ªõi h∆∞·ªõng d·∫´n chi ti·∫øt.
"""

import cv2
import numpy as np
from PySide6.QtCore import Qt, Signal, Slot
from PySide6.QtGui import QImage, QPixmap, QColor
from PySide6.QtWidgets import (
    QWidget,
    QVBoxLayout,
    QHBoxLayout,
    QLabel,
    QPushButton,
    QFrame,
    QGraphicsDropShadowEffect,
)

from UI.styles import Theme
from common.camera import CameraThread
from modules.face_analyzer import DistanceStatus, PoseType
from .face_processing_thread import FaceProcessingThread


class CaptureStep(QWidget):
    """B∆∞·ªõc 2: ch·ª•p 5 g√≥c khu√¥n m·∫∑t."""

    finished = Signal(list)  # (pose_type, embedding, cropped_image)

    DISTANCE_STABLE_REQUIRED = 3  # C·∫ßn kho·∫£ng c√°ch OK ·ªïn ƒë·ªãnh N l·∫ßn tr∆∞·ªõc khi cho ch·ª•p

    POSE_SEQUENCE = [
        PoseType.FRONTAL,
        PoseType.LEFT,
        PoseType.RIGHT,
        PoseType.UP,
        PoseType.DOWN
    ]

    POSE_NAMES = {
        PoseType.FRONTAL: "Nh√¨n th·∫≥ng",
        PoseType.LEFT: "Xoay tr√°i",
        PoseType.RIGHT: "Xoay ph·∫£i",
        PoseType.UP: "Ng·∫©ng l√™n",
        PoseType.DOWN: "C√∫i xu·ªëng",
    }

    def __init__(self):
        super().__init__()
        self.current_step_index = 0
        self.captured_data: list[tuple[PoseType, np.ndarray, np.ndarray]] = []
        self.latest_frame: np.ndarray | None = None  # L∆∞u frame m·ªõi nh·∫•t
        self.last_yaw: float | None = None  # Kh·ªüi t·∫°o last_yaw
        self._distance_ok_stable = 0

        self.camera_thread: CameraThread | None = None
        self.processor_thread = FaceProcessingThread()
        self.processor_thread.result_ready.connect(self._on_ai_result)
        self.processor_thread.model_loaded.connect(self._on_models_loaded)
        self.processor_thread.start()

        self.last_ai_result = {}  # Initialize as empty dict for new logic

        self._build_ui()

    # ------------------------------- UI setup ------------------------------- #
    def _build_ui(self):
        layout = QHBoxLayout(self)
        layout.setSpacing(30)

        # Panel camera
        camera_container = QFrame()
        camera_container.setProperty("class", "glass_panel")
        camera_layout = QVBoxLayout(camera_container)
        camera_layout.setAlignment(Qt.AlignCenter)

        # Khung ngo√†i 2 l·ªõp (outer frame)
        self.camera_frame = QFrame()
        self.camera_frame.setFixedSize(410, 410)
        self.camera_frame.setStyleSheet(
            f"""
            QFrame {{
                background-color: transparent;
                border: 2px solid {Theme.BORDER_COLOR};
                border-radius: 16px;
            }}
            """
        )
        frame_layout = QVBoxLayout(self.camera_frame)
        frame_layout.setContentsMargins(6, 6, 6, 6)
        frame_layout.setAlignment(Qt.AlignCenter)

        # Khung trong (inner view)
        self.camera_view = QLabel()
        self.camera_view.setAlignment(Qt.AlignCenter)
        self.camera_view.setFixedSize(400, 400)
        self.camera_view.setStyleSheet(
            f"background-color: #000; border: 4px solid {Theme.PRIMARY}; border-radius: 12px;"
        )
        frame_layout.addWidget(self.camera_view)
        camera_layout.addWidget(self.camera_frame)

        self.instruction_label = QLabel("ƒêang t·∫£i m√¥ h√¨nh AI...")
        self.instruction_label.setAlignment(Qt.AlignCenter)
        self.instruction_label.setStyleSheet(
            f"color: {Theme.PRIMARY}; font-size: 22px; font-weight: bold; padding: 15px;"
        )
        shadow = QGraphicsDropShadowEffect()
        shadow.setBlurRadius(15)
        shadow.setColor(QColor(Theme.PRIMARY))
        shadow.setOffset(0, 0)
        self.instruction_label.setGraphicsEffect(shadow)
        camera_layout.addWidget(self.instruction_label)

        self.distance_label = QLabel("Vui l√≤ng ch·ªù...")
        self.distance_label.setAlignment(Qt.AlignCenter)
        self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
        camera_layout.addWidget(self.distance_label)

        # N√öt Ch·ª•p th·ªß c√¥ng
        self.capture_btn = QPushButton("üì∏ Ch·ª•p")
        self.capture_btn.setFixedHeight(60)
        self.capture_btn.setStyleSheet(f"""
            QPushButton {{
                background-color: {Theme.PRIMARY};
                color: white;
                font-size: 20px;
                font-weight: bold;
                border: none;
                border-radius: 8px;
                padding: 10px;
            }}
            QPushButton:hover {{
                background-color: {Theme.SECONDARY_GREEN};
            }}
            QPushButton:disabled {{
                background-color: #555;
                color: #999;
            }}
        """)
        self.capture_btn.clicked.connect(self._on_manual_capture)
        self.capture_btn.setEnabled(False)
        camera_layout.addWidget(self.capture_btn)

        layout.addWidget(camera_container, 2)

        # Panel checklist
        checklist_container = QFrame()
        checklist_container.setProperty("class", "glass_panel")
        checklist_layout = QVBoxLayout(checklist_container)
        checklist_layout.setContentsMargins(20, 20, 20, 20)

        header = QLabel("Ti·∫øn tr√¨nh quay c√°c g√≥c")
        header.setStyleSheet(
            f"color: {Theme.TEXT_WHITE}; font-size: 18px; font-weight: bold;"
        )
        checklist_layout.addWidget(header)

        self.checklist_labels: dict[PoseType, QLabel] = {}
        for pose in self.POSE_SEQUENCE:
            lbl = QLabel(f"‚¨ú  {self.POSE_NAMES[pose]}")
            lbl.setStyleSheet(
                f"color: {Theme.TEXT_GRAY}; font-size: 16px; padding: 8px;"
            )
            self.checklist_labels[pose] = lbl
            checklist_layout.addWidget(lbl)

        checklist_layout.addStretch()

        cancel_btn = QPushButton("H·ªßy")
        cancel_btn.setProperty("class", "danger_button")
        cancel_btn.clicked.connect(self._on_cancel)
        checklist_layout.addWidget(cancel_btn)

        layout.addWidget(checklist_container, 1)

    # -------------------------- Capture life-cycle -------------------------- #
    def _on_models_loaded(self, success: bool, msg: str):
        if success:
            self.instruction_label.setText("S·∫µn s√†ng!")
            self.distance_label.setText("")
        else:
            self.instruction_label.setText("L·ªói AI!")
            self.distance_label.setText(msg)

    def start_capture(self, user_id: str = "temp"):
        self.user_id = user_id
        self.current_step_index = 0
        self.captured_data.clear()
        self._reset_checklist()
        
        # Reset baseline pose t·ª´ FRONTAL
        self.processor_thread.reset_pose_state()

        self.camera_view.setText("‚åõ\n\nƒêang kh·ªüi ƒë·ªông camera...")
        self.camera_view.setStyleSheet(
            f"background-color: #000; border: 4px solid {Theme.PRIMARY}; border-radius: 12px; "
            f"color: {Theme.TEXT_GRAY}; font-size: 16px;"
        )

        if self.camera_thread is None or not self.camera_thread.isRunning():
            self.camera_thread = CameraThread()
            self.camera_thread.frame_captured.connect(self._on_frame)
            self.camera_thread.error_occurred.connect(self._on_camera_error)
            self.camera_thread.started.connect(self._on_camera_started)
            self.camera_thread.start()

    def stop(self):
        if self.camera_thread:
            self.camera_thread.stop()

    def reset_ui(self):
        self.stop()
        self._reset_checklist()
        self.current_step_index = 0
        self.captured_data.clear()
        self.camera_view.clear()
        self.instruction_label.setText("Chu·∫©n b·ªã...")
        self.distance_label.clear()

    def _on_camera_started(self):
        # Clear text trong camera_view ƒë·ªÉ s·∫µn s√†ng hi·ªÉn th·ªã frame
        self.camera_view.clear()
        self.camera_view.setStyleSheet(
            f"background-color: #000; border: 4px solid {Theme.PRIMARY}; border-radius: 12px;"
        )
        self.distance_label.setText("")
        self._update_instruction()

    def _reset_checklist(self):
        for pose, lbl in self.checklist_labels.items():
            lbl.setText(f"‚¨ú  {self.POSE_NAMES[pose]}")
            lbl.setStyleSheet(
                f"color: {Theme.TEXT_GRAY}; font-size: 16px; padding: 8px;"
            )

    def _update_instruction(self):
        if self.current_step_index >= len(self.POSE_SEQUENCE):
            self.instruction_label.setText("‚úÖ Ho√†n t·∫•t!")
            return
        
        current_pose = self.POSE_SEQUENCE[self.current_step_index]
        pose_name = self.POSE_NAMES[current_pose]
        step_num = self.current_step_index + 1
        total = len(self.POSE_SEQUENCE)

        instructions = {
            PoseType.FRONTAL: "üë§ NH√åN TH·∫≤NG v√†o camera",
            PoseType.LEFT: "üëà XOAY M·∫∂T SANG TR√ÅI",
            PoseType.RIGHT: "üëâ XOAY M·∫∂T SANG PH·∫¢I",
            PoseType.UP: "‚¨ÜÔ∏è NG·∫®NG ƒê·∫¶U L√äN",
            PoseType.DOWN: "‚¨áÔ∏è C√öI ƒê·∫¶U XU·ªêNG",
        }

        msg = f"{step_num}/{total}: {pose_name}\n\n{instructions.get(current_pose, '')}\n\nüëâ Nh·∫•n n√∫t CH·ª§P khi s·∫µn s√†ng"
        self.instruction_label.setText(msg)

    # ------------------------------- Frame loop ------------------------------ #
    @Slot(np.ndarray)
    def _on_frame(self, frame: np.ndarray):
        self.latest_frame = frame.copy()  # L∆∞u frame m·ªõi nh·∫•t
        if self.current_step_index >= len(self.POSE_SEQUENCE):
            return
        if self.processor_thread.is_models_loaded:
            current_pose = self.POSE_SEQUENCE[self.current_step_index]
            self.processor_thread.update_frame(frame, current_pose)
        self._draw_ui_overlay(frame)

    def _on_ai_result(self, result: dict):
        self.last_ai_result = result
        
        distance_status = result["distance_status"]
        pose_instruction = result["pose_instruction"]
        pose_ok = result["pose_ok"]
        self.last_yaw = result["yaw"]
        
        # C·∫≠p nh·∫≠t UI h∆∞·ªõng d·∫´n + ·ªïn ƒë·ªãnh kho·∫£ng c√°ch
        if distance_status != DistanceStatus.OK:
            self._distance_ok_stable = 0

        if distance_status == DistanceStatus.NO_FACE:
            self.distance_label.setText("‚ùå Kh√¥ng th·∫•y khu√¥n m·∫∑t")
            self.distance_label.setStyleSheet("color: #FF6B6B; font-size: 16px;")
            self.capture_btn.setEnabled(False)
        elif distance_status == DistanceStatus.TOO_FAR:
            self.distance_label.setText(f"‚ö†Ô∏è {pose_instruction}")
            self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
            self.capture_btn.setEnabled(False)
        elif distance_status == DistanceStatus.TOO_CLOSE:
            self.distance_label.setText(f"‚ö†Ô∏è {pose_instruction}")
            self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
            self.capture_btn.setEnabled(False)
        else:
            self._distance_ok_stable += 1
            # Distance OK -> Check Pose
            if pose_ok and self._distance_ok_stable >= self.DISTANCE_STABLE_REQUIRED:
                self.distance_label.setText(f"‚úÖ {pose_instruction}")
                self.distance_label.setStyleSheet(f"color: {Theme.SECONDARY_GREEN}; font-size: 16px;")
                self.capture_btn.setEnabled(True)
            elif pose_ok:
                self.distance_label.setText(f"‚úÖ {pose_instruction} (Gi·ªØ kho·∫£ng c√°ch ·ªïn ƒë·ªãnh)")
                self.distance_label.setStyleSheet(f"color: {Theme.SECONDARY_GREEN}; font-size: 16px;")
                self.capture_btn.setEnabled(False)
            else:
                self.distance_label.setText(f"‚ÑπÔ∏è {pose_instruction}")
                self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
                self.capture_btn.setEnabled(False)

    def _on_manual_capture(self):
        """X·ª≠ l√Ω khi ng∆∞·ªùi d√πng nh·∫•n n√∫t Ch·ª•p - T·ªëi ∆∞u h√≥a: D√πng lu√¥n k·∫øt qu·∫£ AI ƒë√£ cache."""
        # L·∫•y k·∫øt qu·∫£ AI m·ªõi nh·∫•t
        if not self.last_ai_result or not self.last_ai_result.get("has_face"):
             self.distance_label.setText("‚ùå Ch∆∞a c√≥ d·ªØ li·ªáu khu√¥n m·∫∑t")
             return

        # Ki·ªÉm tra l·∫°i tr·∫°ng th√°i l·∫ßn cu·ªëi (an to√†n)
        dist_status = self.last_ai_result["distance_status"]
        pose_ok = self.last_ai_result["pose_ok"]
        
        if dist_status != DistanceStatus.OK:
             self.distance_label.setText("‚ùå Kho·∫£ng c√°ch kh√¥ng h·ª£p l·ªá")
             return
             
        # L·∫•y d·ªØ li·ªáu ƒë√£ t√≠nh to√°n s·∫µn
        embedding = self.last_ai_result["embedding"]
        face_box = self.last_ai_result["face_box"]
        frame_analyzed = self.last_ai_result["frame"] # Frame ƒë·ªìng b·ªô v·ªõi k·∫øt qu·∫£ AI
        
        if embedding is None or frame_analyzed is None:
             self.distance_label.setText("‚ùå D·ªØ li·ªáu l·ªói (No embedding/frame)")
             return

        # Crop khu√¥n m·∫∑t t·ª´ frame ƒë√£ analyze (ƒë·∫£m b·∫£o box n·∫±m trong bi√™n ·∫£nh)
        x, y, w, h = face_box
        img_h, img_w = frame_analyzed.shape[:2]

        # N·ªõi r·ªông box m·ªôt ch√∫t ƒë·ªÉ crop tho√°ng h∆°n, r·ªìi clamp l·∫°i bi√™n ·∫£nh
        pad_w = int(w * 0.15)
        pad_h = int(h * 0.20)

        x1 = max(0, int(x - pad_w))
        y1 = max(0, int(y - pad_h))
        x2 = min(img_w, int(x + w + pad_w))
        y2 = min(img_h, int(y + h + pad_h))

        if x2 <= x1 or y2 <= y1:
            self.distance_label.setText("‚ùå L·ªói h·ªôp khu√¥n m·∫∑t (ngo√†i bi√™n)")
            return

        cropped = frame_analyzed[y1:y2, x1:x2]
        
        if cropped.size == 0:
             self.distance_label.setText("‚ùå L·ªói c·∫Øt ·∫£nh")
             return

        # L∆∞u d·ªØ li·ªáu
        current_pose = self.POSE_SEQUENCE[self.current_step_index]
        self.captured_data.append((current_pose, embedding, cropped))
        self._mark_step_done(current_pose)
        
        # Hi·ªáu ·ª©ng ch·ª•p (Optional: Playsound or Flash)
        
        # Chuy·ªÉn b∆∞·ªõc ti·∫øp theo
        self.current_step_index += 1
        if self.current_step_index >= len(self.POSE_SEQUENCE):
            self.stop()
            self.finished.emit(self.captured_data)
        else:
            self._update_instruction()
            self.capture_btn.setEnabled(False)

    def _draw_ui_overlay(self, frame: np.ndarray):
        if not self.last_ai_result:
            self._display_frame(frame)
            return

        display_frame = frame.copy()
        
        # L·∫•y tr·∫°ng th√°i t·ª´ dict result (c√≥ th·ªÉ l√† c·ªßa frame tr∆∞·ªõc, nh∆∞ng d√πng ƒë·ªÉ v·∫Ω overlay cho frame hi·ªán t·∫°i)
        # L∆∞u √Ω: frame input c·ªßa h√†m n√†y l√† frame M·ªöI NH·∫§T t·ª´ camera, kh√¥ng ph·∫£i frame trong result.
        # Overlay c√≥ th·ªÉ b·ªã l·ªách nh·∫π n·∫øu v·∫≠t th·ªÉ di chuy·ªÉn nhanh, nh∆∞ng ch·∫•p nh·∫≠n ƒë∆∞·ª£c cho realtime feedback.
        
        dist_status = self.last_ai_result.get("distance_status", DistanceStatus.NO_FACE)
        pose_ok = self.last_ai_result.get("pose_ok", False)
        
        border_color = Theme.DANGER_RED
        if dist_status == DistanceStatus.OK and pose_ok:
            border_color = Theme.SECONDARY_GREEN
        elif dist_status == DistanceStatus.OK:
            border_color = "#FFD700" # Warning color for wrong pose
            
        h, w = display_frame.shape[:2]
        color_bgr = self._hex_to_bgr(border_color)

        # V·∫Ω khung oval h∆∞·ªõng d·∫´n 1 vi·ªÅn l√† ƒë·ªß
        min_dim = min(h, w)
        center = (w // 2, h // 2)
        axes = (int(min_dim * 0.36), int(min_dim * 0.48))
        cv2.ellipse(display_frame, center, axes, 0, 0, 360, color_bgr, 4)

        # Hi·ªÉn th·ªã gi√° tr·ªã Ratio ·ªü g√≥c d∆∞·ªõi b√™n tr√°i ƒë·ªÉ debug
        yaw_text = "Ratio: --"
        if self.last_yaw is not None:
            yaw_text = f"Ratio: {self.last_yaw:.2f}"
        
        cv2.putText(
            display_frame,
            yaw_text,
            (20, h - 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            self._hex_to_bgr("#FFFFFF"),
            2,
            cv2.LINE_AA,
        )

        self._display_frame(display_frame)

    # ------------------------- Capture & finish flow ------------------------ #
    def _mark_step_done(self, pose: PoseType):
        """ƒê√°nh d·∫•u b∆∞·ªõc ƒë√£ ho√†n th√†nh."""
        lbl = self.checklist_labels[pose]
        lbl.setText(f"‚úÖ  {self.POSE_NAMES[pose]}")
        lbl.setStyleSheet(
            f"color: {Theme.SECONDARY_GREEN}; font-size: 16px; padding: 8px; font-weight: bold;"
        )

    def _on_cancel(self):
        self.stop()
        self.finished.emit([])

    def _on_camera_error(self, msg: str):
        self.instruction_label.setText(f"L·ªói camera: {msg}")
        self.distance_label.setText("Vui l√≤ng ki·ªÉm tra l·∫°i camera.")

    # -------------------------- Helper hi·ªÉn th·ªã ----------------------------- #
    def _display_frame(self, frame: np.ndarray):
        # ƒê·∫£m b·∫£o clear text n·∫øu c√≤n (first frame)
        if self.camera_view.text():
            self.camera_view.clear()
            self.camera_view.setStyleSheet(
                f"background-color: #000; border: 4px solid {Theme.PRIMARY}; border-radius: 12px;"
            )
        
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb.shape
        bytes_per_line = ch * w
        q_img = QImage(rgb.data, w, h, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_img)
        scaled = pixmap.scaled(
            400, 400, Qt.KeepAspectRatioByExpanding, Qt.SmoothTransformation
        )
        self.camera_view.setPixmap(scaled)

    def _hex_to_bgr(self, hex_color: str) -> tuple[int, int, int]:
        hex_color = hex_color.lstrip("#")
        r = int(hex_color[0:2], 16)
        g = int(hex_color[2:4], 16)
        b = int(hex_color[4:6], 16)
        return b, g, r
