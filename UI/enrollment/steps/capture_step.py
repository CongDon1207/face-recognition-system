"""
Step 2: Capture Sequence - Chá»¥p khuÃ´n máº·t theo cÃ¡c gÃ³c khÃ¡c nhau.
TÃ­ch há»£p Camera, Head Pose Detection, Distance Check.
"""
from PySide6.QtWidgets import (QWidget, QVBoxLayout, QHBoxLayout, QLabel, 
                               QPushButton, QFrame, QGraphicsDropShadowEffect)
from PySide6.QtCore import Qt, Signal, Slot, QTimer, QThread, QMutex, QWaitCondition
from PySide6.QtGui import QImage, QPixmap, QColor
from UI.styles import Theme
from common.camera import CameraThread
from modules.face_analyzer import FaceAnalyzer, DistanceStatus, PoseType
import numpy as np
import cv2
import time


class FaceProcessingThread(QThread):
    """
    Thread xá»­ lÃ½ AI (Detection, Pose, Embedding) Ä‘á»ƒ khÃ´ng block Main UI.
    """
    model_loaded = Signal(bool, str)  # success, message
    result_ready = Signal(object, object, object)  # distance_status, pose_info, face_box
    
    def __init__(self):
        super().__init__()
        self.face_analyzer = None
        self.running = True
        self.latest_frame = None
        self.target_pose = None
        self.frame_mutex = QMutex()
        self.condition = QWaitCondition()
        self.is_models_loaded = False

    def initialize_models(self):
        """Khá»Ÿi táº¡o models (cháº¡y trong thread)."""
        try:
            if self.face_analyzer is None:
                self.face_analyzer = FaceAnalyzer()
            # Force load models immediately
            self.face_analyzer._ensure_models()
            self.is_models_loaded = True
            self.model_loaded.emit(True, "Models loaded successfully")
        except Exception as e:
            print(f"Error loading models: {e}")
            self.model_loaded.emit(False, str(e))

    def update_frame(self, frame, target_pose):
        """Cáº­p nháº­t frame má»›i nháº¥t Ä‘á»ƒ xá»­ lÃ½."""
        if not self.is_models_loaded:
            return

        self.frame_mutex.lock()
        self.latest_frame = frame.copy()
        self.target_pose = target_pose
        self.frame_mutex.unlock()
        self.condition.wakeOne()

    def run(self):
        # 1. Init models first
        self.initialize_models()
        
        while self.running:
            self.frame_mutex.lock()
            if self.latest_frame is None:
                self.condition.wait(self.frame_mutex)
            
            if self.latest_frame is None or not self.running:
                self.frame_mutex.unlock()
                continue
                
            frame = self.latest_frame
            target_pose = self.target_pose
            self.latest_frame = None  # Clear buffer
            self.frame_mutex.unlock()
            
            # 2. Process frame (Heavy work)
            if self.is_models_loaded:
                try:
                    # Check distance
                    distance_status = self.face_analyzer.check_face_distance(frame)
                    face_box = self.face_analyzer._last_face_box
                    
                    # Check pose if distance is OK
                    pose_result = None
                    if distance_status == DistanceStatus.OK and target_pose:
                        pose_result = self.face_analyzer.check_pose(frame, target_pose)
                        
                    self.result_ready.emit(distance_status, pose_result, face_box)
                    
                except Exception as e:
                    print(f"Processing error: {e}")
        
    def stop(self):
        self.running = False
        self.condition.wakeOne()
        self.wait()

    def get_embedding(self, frame):
        # Helper sync call for final capture (rarely called)
        if self.face_analyzer:
            return self.face_analyzer.get_embedding(frame)
        return None

    def get_face_crop(self, frame):
         if self.face_analyzer:
            return self.face_analyzer.get_face_crop(frame)
         return None


class CaptureStep(QWidget):
    """BÆ°á»›c 2: Chá»¥p áº£nh khuÃ´n máº·t theo 5 gÃ³c."""
    finished = Signal(list)  # Emit danh sÃ¡ch (pose_type, embedding, image_path)

    POSE_SEQUENCE = [
        PoseType.FRONTAL,
        PoseType.LEFT,
        PoseType.RIGHT,
        PoseType.UP,
        PoseType.DOWN
    ]

    def __init__(self):
        super().__init__()
        self.current_step_index = 0
        self.captured_data = []  # LÆ°u (pose_type, embedding, cropped_image)
        self.hold_timer = QTimer()
        self.hold_timer.timeout.connect(self._on_hold_complete)
        self.hold_counter = 0
        
        self.camera_thread = None
        self.processor_thread = FaceProcessingThread()
        self.processor_thread.result_ready.connect(self._on_ai_result)
        self.processor_thread.model_loaded.connect(self._on_models_loaded)
        self.processor_thread.start() # Start immediately to load models
        
        self.is_processing_frame = False
        self.last_ai_result = (DistanceStatus.NO_FACE, None, None) # Cache result
        
        self.init_ui()

    def init_ui(self):
        layout = QHBoxLayout(self)
        layout.setSpacing(30)
        
        # -- Left: Camera Area --
        camera_container = QFrame()
        camera_container.setProperty("class", "glass_panel")
        camera_layout = QVBoxLayout(camera_container)
        camera_layout.setAlignment(Qt.AlignCenter)
        
        # Khung camera (sáº½ hiá»ƒn thá»‹ feed)
        self.camera_view = QLabel()
        self.camera_view.setAlignment(Qt.AlignCenter)
        self.camera_view.setFixedSize(400, 400)
        self.camera_view.setStyleSheet(f"""
            background-color: #000; 
            border: 3px solid {Theme.PRIMARY};
            border-radius: 200px;
        """)
        camera_layout.addWidget(self.camera_view)
        
        # Instruction Label - Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n lá»›n
        self.instruction_label = QLabel("Äang táº£i AI...")
        self.instruction_label.setAlignment(Qt.AlignCenter)
        self.instruction_label.setStyleSheet(f"""
            color: {Theme.PRIMARY}; 
            font-size: 22px; 
            font-weight: bold;
            padding: 15px;
        """)
        # ThÃªm shadow
        shadow = QGraphicsDropShadowEffect()
        shadow.setBlurRadius(15)
        shadow.setColor(QColor(Theme.PRIMARY))
        shadow.setOffset(0, 0)
        self.instruction_label.setGraphicsEffect(shadow)
        camera_layout.addWidget(self.instruction_label)
        
        # Distance feedback label
        self.distance_label = QLabel("Vui lÃ²ng Ä‘á»£i...")
        self.distance_label.setAlignment(Qt.AlignCenter)
        self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
        camera_layout.addWidget(self.distance_label)
        
        layout.addWidget(camera_container, 2)
        
        # -- Right: Checklist --
        checklist_container = QFrame()
        checklist_container.setProperty("class", "glass_panel")
        checklist_layout = QVBoxLayout(checklist_container)
        checklist_layout.setContentsMargins(20, 20, 20, 20)
        
        checklist_header = QLabel("Tiáº¿n trÃ¬nh quÃ©t")
        checklist_header.setStyleSheet(f"color: {Theme.TEXT_WHITE}; font-size: 18px; font-weight: bold;")
        checklist_layout.addWidget(checklist_header)
        
        # Táº¡o label cho tá»«ng gÃ³c
        self.checklist_labels = {}
        pose_names = {
            PoseType.FRONTAL: "NhÃ¬n tháº³ng",
            PoseType.LEFT: "NghiÃªng trÃ¡i",
            PoseType.RIGHT: "NghiÃªng pháº£i",
            PoseType.UP: "Ngáº©ng lÃªn",
            PoseType.DOWN: "CÃºi xuá»‘ng"
        }
        for pose in self.POSE_SEQUENCE:
            lbl = QLabel(f"â—‹  {pose_names[pose]}")
            lbl.setStyleSheet(f"color: {Theme.TEXT_GRAY}; font-size: 16px; padding: 8px;")
            self.checklist_labels[pose] = lbl
            checklist_layout.addWidget(lbl)
            
        checklist_layout.addStretch()
        
        # NÃºt Cancel (debug)
        cancel_btn = QPushButton("Há»§y")
        cancel_btn.setProperty("class", "danger_button")
        cancel_btn.clicked.connect(self._on_cancel)
        checklist_layout.addWidget(cancel_btn)
        
        layout.addWidget(checklist_container, 1)

    def _on_models_loaded(self, success, msg):
        if success:
            self.instruction_label.setText("Sáºµn sÃ ng!")
            self.distance_label.setText("")
        else:
            self.instruction_label.setText("Lá»—i AI!")
            self.distance_label.setText(msg)

    def start_capture(self, user_id: str = "temp"):
        """Báº¯t Ä‘áº§u quy trÃ¬nh capture."""
        self.user_id = user_id
        self.current_step_index = 0
        self.captured_data = []
        self._reset_checklist()
        
        # Hiá»ƒn thá»‹ loading state
        self.camera_view.setText("ðŸ“·\n\nÄang khá»Ÿi Ä‘á»™ng camera...")
        self.camera_view.setStyleSheet(f"""
            background-color: #000; 
            border: 3px solid {Theme.PRIMARY};
            border-radius: 200px;
            color: {Theme.TEXT_GRAY};
            font-size: 16px;
        """)
        
        # Khá»Ÿi Ä‘á»™ng camera
        if self.camera_thread is None or not self.camera_thread.isRunning():
            self.camera_thread = CameraThread()
            self.camera_thread.frame_captured.connect(self._on_frame)
            self.camera_thread.error_occurred.connect(self._on_camera_error)
            self.camera_thread.started.connect(self._on_camera_started)
            self.camera_thread.start()

    def stop(self):
        """Dá»«ng camera vÃ  reset."""
        if self.camera_thread:
            self.camera_thread.stop()
        self.hold_timer.stop()
        # Note: We don't stop processor_thread here to keep models loaded

    def reset_ui(self):
        """Reset UI vá» tráº¡ng thÃ¡i ban Ä‘áº§u."""
        self.stop()
        self._reset_checklist()
        self.current_step_index = 0
        self.captured_data = []
        self.camera_view.clear()
        self.instruction_label.setText("Chuáº©n bá»‹...")
        self.distance_label.clear()

    def _on_camera_started(self):
        """Callback khi camera Ä‘Ã£ sáºµn sÃ ng."""
        self.distance_label.setText("")
        self._update_instruction()

    def _reset_checklist(self):
        """Reset táº¥t cáº£ cÃ¡c checkbox vá» tráº¡ng thÃ¡i chÆ°a hoÃ n thÃ nh."""
        pose_names = {
            PoseType.FRONTAL: "NhÃ¬n tháº³ng",
            PoseType.LEFT: "NghiÃªng trÃ¡i",
            PoseType.RIGHT: "NghiÃªng pháº£i",
            PoseType.UP: "Ngáº©ng lÃªn",
            PoseType.DOWN: "CÃºi xuá»‘ng"
        }
        for pose, lbl in self.checklist_labels.items():
            lbl.setText(f"â—‹  {pose_names[pose]}")
            lbl.setStyleSheet(f"color: {Theme.TEXT_GRAY}; font-size: 16px; padding: 8px;")

    def _update_instruction(self):
        """Cáº­p nháº­t hÆ°á»›ng dáº«n cho bÆ°á»›c hiá»‡n táº¡i."""
        if self.current_step_index >= len(self.POSE_SEQUENCE):
            self.instruction_label.setText("HoÃ n táº¥t!")
            return
        
        instructions = {
            PoseType.FRONTAL: "NHÃŒN THáº²NG vÃ o camera",
            PoseType.LEFT: "QUAY Äáº¦U SANG TRÃI",
            PoseType.RIGHT: "QUAY Äáº¦U SANG PHáº¢I",
            PoseType.UP: "NGáº¨NG Äáº¦U LÃŠN",
            PoseType.DOWN: "CÃšI Äáº¦U XUá»NG"
        }
        current_pose = self.POSE_SEQUENCE[self.current_step_index]
        self.instruction_label.setText(instructions[current_pose])

    @Slot(np.ndarray)
    def _on_frame(self, frame: np.ndarray):
        """Xá»­ lÃ½ má»—i frame tá»« camera."""
        if self.current_step_index >= len(self.POSE_SEQUENCE):
            return
        
        # Send to AI thread (non-blocking)
        if self.processor_thread.is_models_loaded:
             current_pose = self.POSE_SEQUENCE[self.current_step_index]
             self.processor_thread.update_frame(frame, current_pose)

        # Draw UI based on LAST KNOWN result
        self._draw_ui_overlay(frame)
        
    def _on_ai_result(self, distance_status, pose_result, face_box):
        """Nháº­n káº¿t quáº£ tá»« AI thread."""
        self.last_ai_result = (distance_status, pose_result, face_box)
        
        # Logic check status (chá»‰ update text/timer, khÃ´ng váº½ frame á»Ÿ Ä‘Ã¢y)
        if distance_status == DistanceStatus.NO_FACE:
            self.distance_label.setText("âš  KhÃ´ng tháº¥y khuÃ´n máº·t")
            self.distance_label.setStyleSheet("color: #FF6B6B; font-size: 16px;")
            self.hold_timer.stop()
            self.hold_counter = 0
            
        elif distance_status == DistanceStatus.TOO_FAR:
            self.distance_label.setText("â†‘ Láº¡i gáº§n hÆ¡n")
            self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
            self.hold_timer.stop()
            self.hold_counter = 0
            
        elif distance_status == DistanceStatus.TOO_CLOSE:
            self.distance_label.setText("â†“ Ra xa má»™t chÃºt")
            self.distance_label.setStyleSheet("color: #FFD700; font-size: 16px;")
            self.hold_timer.stop()
            self.hold_counter = 0
            
        else: # OK
            self.distance_label.setText("âœ“ Khoáº£ng cÃ¡ch OK")
            self.distance_label.setStyleSheet(f"color: {Theme.SECONDARY_GREEN}; font-size: 16px;")
            
            if pose_result:
                pose_ok, msg = pose_result
                if pose_ok:
                    if not self.hold_timer.isActive():
                        self.hold_counter = 0
                        self.hold_timer.start(500)
                        self.instruction_label.setText("Giá»¯ yÃªn...")
                else:
                    self.hold_timer.stop()
                    self.hold_counter = 0
                    self.instruction_label.setText(msg)

    def _draw_ui_overlay(self, frame):
        """Váº½ overlay lÃªn frame dá»±a trÃªn káº¿t quáº£ AI gáº§n nháº¥t."""
        display_frame = frame.copy()
        
        distance_status, pose_result, face_box = self.last_ai_result
        border_color = Theme.DANGER_RED

        if distance_status == DistanceStatus.OK:
            if pose_result and pose_result[0]: # pose_ok
                border_color = Theme.SECONDARY_GREEN
            
        # Váº½ border indicator
        h, w = display_frame.shape[:2]
        color_bgr = self._hex_to_bgr(border_color)
        cv2.rectangle(display_frame, (10, 10), (w-10, h-10), color_bgr, 3)
        
        # Váº½ face box náº¿u cÃ³
        # if face_box:
        #     x, y, w, h = face_box
        #     cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 1)

        self._display_frame(display_frame)

    def _on_hold_complete(self):
        """Callback khi user giá»¯ yÃªn Ä‘á»§ lÃ¢u."""
        self.hold_counter += 1
        if self.hold_counter >= 2:  # Giá»¯ 1.0 giÃ¢y (nhanh hÆ¡n)
            self.hold_timer.stop()
            self._capture_current_pose()

    def _capture_current_pose(self):
        """Chá»¥p vÃ  lÆ°u embedding cho pose hiá»‡n táº¡i."""
        # Láº¥y frame hiá»‡n táº¡i tá»« camera thread
        if self.camera_thread and self.camera_thread._cap:
            ret, frame = self.camera_thread._cap.read()
            if ret:
                # frame = cv2.flip(frame, 1) # REMOVED: CameraThread already flips
                current_pose = self.POSE_SEQUENCE[self.current_step_index]
                
                # Embedding láº¥y sync tá»« thread (vÃ¬ chá»‰ cáº§n lÃ m 1 láº§n)
                # Hoáº·c dÃ¹ng processor thread nhÆ°ng pháº£i wait. 
                # á»ž Ä‘Ã¢y gá»i hÃ m helper cá»§a thread (cháº¡y sync trong thread nÃ y hoáº·c thread kia? 
                # FaceAnalyzer khÃ´ng thread-safe tuyá»‡t Ä‘á»‘i náº¿u gá»i cÃ¹ng lÃºc.
                # Tuy nhiÃªn lÃºc nÃ y ta Ä‘Ã£ stop timer, vÃ  hy vá»ng on_frame khÃ´ng gá»­i thÃªm request quan trá»ng.
                # Äá»ƒ an toÃ n, ta dÃ¹ng lock trong processor thread hoáº·c pause nÃ³.
                
                # CÃ¡ch Ä‘Æ¡n giáº£n: Gá»i trá»±c tiáº¿p processor_thread.get_embedding (bÃªn trong check exist)
                # Rá»§i ro race condition tháº¥p vÃ¬ get_embedding chá»‰ Ä‘á»c model.
                
                embedding = self.processor_thread.get_embedding(frame)
                cropped = self.processor_thread.get_face_crop(frame)
                
                if embedding is not None and cropped is not None:
                    self.captured_data.append((current_pose, embedding, cropped))
                    self._mark_step_complete(current_pose)
                    self.current_step_index += 1
                    
                    if self.current_step_index >= len(self.POSE_SEQUENCE):
                        self._on_all_complete()
                    else:
                        self._update_instruction()
                        # Reset result Ä‘á»ƒ trÃ¡nh tá»± Ä‘á»™ng trigger tiáº¿p
                        self.last_ai_result = (DistanceStatus.NO_FACE, None, None)

    def _mark_step_complete(self, pose: PoseType):
        """ÄÃ¡nh dáº¥u bÆ°á»›c Ä‘Ã£ hoÃ n thÃ nh."""
        pose_names = {
            PoseType.FRONTAL: "NhÃ¬n tháº³ng",
            PoseType.LEFT: "NghiÃªng trÃ¡i",
            PoseType.RIGHT: "NghiÃªng pháº£i",
            PoseType.UP: "Ngáº©ng lÃªn",
            PoseType.DOWN: "CÃºi xuá»‘ng"
        }
        lbl = self.checklist_labels[pose]
        lbl.setText(f"âœ”  {pose_names[pose]}")
        lbl.setStyleSheet(f"color: {Theme.SECONDARY_GREEN}; font-size: 16px; padding: 8px; font-weight: bold;")

    def _on_all_complete(self):
        """Khi Ä‘Ã£ capture xong táº¥t cáº£ cÃ¡c gÃ³c."""
        self.stop()
        self.instruction_label.setText("âœ“ HoÃ n táº¥t!")
        self.finished.emit(self.captured_data)

    def _on_cancel(self):
        """Há»§y quy trÃ¬nh capture."""
        self.stop()
        self.finished.emit([])  # Emit empty list = cancelled

    def _on_camera_error(self, msg: str):
        """Xá»­ lÃ½ lá»—i camera."""
        self.instruction_label.setText(f"Lá»—i: {msg}")
        self.distance_label.setText("Vui lÃ²ng kiá»ƒm tra camera")

    def _display_frame(self, frame: np.ndarray):
        """Chuyá»ƒn Ä‘á»•i OpenCV frame sang QPixmap vÃ  hiá»ƒn thá»‹."""
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb.shape
        bytes_per_line = ch * w
        q_img = QImage(rgb.data, w, h, bytes_per_line, QImage.Format_RGB888)
        
        # Scale vÃ  crop thÃ nh hÃ¬nh trÃ²n
        pixmap = QPixmap.fromImage(q_img)
        scaled = pixmap.scaled(400, 400, Qt.KeepAspectRatioByExpanding, Qt.SmoothTransformation)
        self.camera_view.setPixmap(scaled)

    def _hex_to_bgr(self, hex_color: str) -> tuple:
        """Chuyá»ƒn hex color sang BGR."""
        hex_color = hex_color.lstrip('#')
        r, g, b = int(hex_color[0:2], 16), int(hex_color[2:4], 16), int(hex_color[4:6], 16)
        return (b, g, r)
